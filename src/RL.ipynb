{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Testing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to perform reinforcement learning on a certain stock. All learning variables are parameters into the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Episode Done: 0\n",
      "Episode Done: 1\n",
      "Episode Done: 2\n",
      "Episode Done: 3\n",
      "Episode Done: 4\n",
      "Episode Done: 5\n",
      "Episode Done: 6\n",
      "Episode Done: 7\n",
      "Episode Done: 8\n",
      "Episode Done: 9\n",
      "Complete\n",
      "wow this actually compiled\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib\n",
    "import reinforcement_learning\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "plt.ion()\n",
    "\n",
    "rl = reinforcement_learning.ReinforcementLearning(GAMMA=0.3, NUM_EPISODES=10, hidden_layer=256, EPS_START=0.9, \n",
    "                                                  EPS_END=0.05, TARGET_UPDATE=1)\n",
    "rl.do_reinforcement_learning()\n",
    "time_series = rl.fd.norm_data_ls[rl.fd.ticker_ls.index(rl.TICKER)]\n",
    "rl.plot_episode(time_series, 1200)\n",
    "print(\"wow this actually compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bellow will evaluate the action for a given reinforcement learning trial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_index = ['Buy', 'Sell', 'Hold']\n",
    "x, y = rl.fd.split_data([rl.fd.norm_data_ls[rl.fd.ticker_ls.index(rl.TICKER)]])\n",
    "state = torch.Tensor(x[0])\n",
    "action_ls = []\n",
    "time_series = rl.fd.norm_data_ls[rl.fd.ticker_ls.index(rl.TICKER)].Close\n",
    "x_coord = np.arange(0, len(time_series))\n",
    "for i in range(0, 100):\n",
    "    action = rl.target_net(Variable(torch.Tensor(x[i])))\n",
    "    action_ls.append(np.argmax(action.data.numpy()))\n",
    "    #print(action_index[np.argmax(action.data.numpy())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = rl.fd.norm_data_ls[rl.fd.ticker_ls.index('AMAT')]\n",
    "rl.plot_episode(time_series, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12c302160>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(rl.loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
